
import os
import datetime
from wave_score import calculate_wave_score
from supabase import create_client, Client
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# Environment variables (use Replit Secrets or .env)
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_ANON_KEY = os.getenv("SUPABASE_ANON_KEY")

# Initialize Supabase
supabase: Client = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)

# Sentiment analyzer
analyzer = SentimentIntensityAnalyzer()

def analyze_sentiment_from_comments(comments):
    sentiment_counts = {"pos": 0, "neg": 0, "neu": 0}
    for comment in comments:
        score = analyzer.polarity_scores(comment)
        if score["compound"] >= 0.05:
            sentiment_counts["pos"] += 1
        elif score["compound"] <= -0.05:
            sentiment_counts["neg"] += 1
        else:
            sentiment_counts["neu"] += 1

    total = sum(sentiment_counts.values())
    if total == 0:
        return 0.5  # neutral default

    sentiment_score = (sentiment_counts["pos"] - sentiment_counts["neg"]) / total
    sentiment_score = max(min((sentiment_score + 1) / 2, 1), 0)  # normalize to 0â€“1
    return round(sentiment_score, 3)

def fetch_mock_reddit_comments(topic):
    # TODO: Replace with real Reddit API fetch
    return [
        f"I love {topic}, it's amazing!",
        f"{topic} is changing everything!",
        f"I'm not sure about {topic}, seems overhyped.",
        f"{topic} sucks, total waste.",
        f"{topic} is the future."
    ]

def fetch_video_metrics(video_id):
    # TODO: Replace with actual Supabase fetch or YouTube API stats
    return {
        "view_count": 2100000,
        "last_view_count": 1200000,
        "likes": 80000,
        "comments": 5000
    }

def analyze_and_store_trend(topic, video_id):
    print(f"ðŸ” Analyzing topic: {topic}")
    reddit_comments = fetch_mock_reddit_comments(topic)
    sentiment_score = analyze_sentiment_from_comments(reddit_comments)

    metrics = fetch_video_metrics(video_id)

    wave_score = calculate_wave_score(
        view_count=metrics["view_count"],
        last_view_count=metrics["last_view_count"],
        likes=metrics["likes"],
        comments=metrics["comments"],
        sentiment_score=sentiment_score
    )

    print(f"âœ… WaveScore for '{topic}' is {wave_score}")

    # Optional: Store in Supabase sentiment_forecasts table
    response = supabase.table("sentiment_forecasts").insert({
        "topic": topic,
        "platform": "Reddit",
        "date": datetime.date.today().isoformat(),
        "sentiment_yes": reddit_comments.count("pos"),
        "sentiment_no": reddit_comments.count("neg"),
        "sentiment_unclear": reddit_comments.count("neu"),
        "confidence": sentiment_score * 100,
        "certainty_score": round(wave_score * 100, 2),
        "prediction_outcome": "Uncertain",
        "cultural_momentum": "Stable",
        "total_responses": len(reddit_comments)
    }).execute()

    print("ðŸ“¡ Stored result in Supabase:", response)

if __name__ == "__main__":
    analyze_and_store_trend("AI art generation", "abc123XYZ")
